---

## ðŸ§ª **EXPERIMENT 1** â€” *Central Tendency and Dispersion*

### Using NumPy

```python
import numpy as np

# Sample data
data = np.array([10, 15, 20, 25, 30, 35, 40, 45, 50])

# Central tendency
mean = np.mean(data)
median = np.median(data)
mode = np.bincount(data).argmax()  # most frequent value

# Dispersion
variance = np.var(data)
std_dev = np.std(data)

# Display results
print("Mean:", mean)
print("Median:", median)
print("Mode:", mode)
print("Variance:", variance)
print("Standard Deviation:", std_dev)
```

---

### Using Pandas

```python
import pandas as pd

# Create dataset
df = pd.DataFrame({"data": [10, 15, 20, 25, 30, 35, 40, 45, 50]})

# Central tendency
mean = df["data"].mean()
median = df["data"].median()
mode = df["data"].mode()[0]

# Dispersion
variance = df["data"].var()
std_dev = df["data"].std()

# Display results
print("Mean:", mean)
print("Median:", median)
print("Mode:", mode)
print("Variance:", variance)
print("Standard Deviation:", std_dev)
```

---

## ðŸ§ª **EXPERIMENT 2** â€” *Using Math, Numpy, Statistics, and SciPy*

### Example (Correlation + Math Operations)

```python
import numpy as np
from scipy.stats import pearsonr

# Two data sets
x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])

# NumPy math operations
print("Sum of x:", np.sum(x))
print("Product of y:", np.prod(y))
print("Square roots of x:", np.sqrt(x))

# Correlation using SciPy
corr, p_value = pearsonr(x, y)
print("Correlation Coefficient:", corr)
print("P-value:", p_value)
```

---

### Example (Normal Distribution)

```python
import numpy as np
import matplotlib.pyplot as plt

# Generate 1000 random numbers (normal distribution)
data = np.random.normal(0, 1, 1000)

plt.hist(data, bins=30, density=True, color='skyblue', edgecolor='black')
plt.title("Normal Distribution")
plt.xlabel("Value")
plt.ylabel("Density")
plt.show()
```

---

## ðŸ§ª **EXPERIMENT 3** â€” *Naive Bayes Classifier (Machine Learning)*

```python
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt

# Load dataset
iris = load_iris()
X = iris.data
y = iris.target

# Visualize (optional)
df = pd.DataFrame(X, columns=iris.feature_names)
df['target'] = y
pd.plotting.scatter_matrix(df, c=y, figsize=(8, 8))
plt.show()

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = GaussianNB()
model.fit(X_train, y_train)

# Predict and evaluate
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
```

---

## ðŸ§ª **EXPERIMENT 4** â€” *Simple Linear Regression*

```python
import numpy as np
import matplotlib.pyplot as plt

# Generate sample data
X = np.random.rand(100) * 10
Y = 2 * X + np.random.normal(0, 1, 100)  # y = 2x + noise

# Find best-fit line
slope, intercept = np.polyfit(X, Y, 1)

# Plot
plt.scatter(X, Y, label="Data Points")
plt.plot(X, slope * X + intercept, color='red', label="Best Fit Line")
plt.xlabel("X")
plt.ylabel("Y")
plt.title("Simple Linear Regression")
plt.legend()
plt.show()
```

---

## ðŸ§ª **EXPERIMENT 5** â€” *Multiple Linear Regression (House Price Prediction)*

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
data = pd.read_csv(url)

# Features and target
X = data.drop('medv', axis=1)
y = data['medv']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate
print("Mean Squared Error:", mean_squared_error(y_test, y_pred))
print("RÂ² Score:", r2_score(y_test, y_pred))

# Plot Actual vs Predicted
sns.regplot(x=y_test, y=y_pred, line_kws={"color": "red"})
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted House Prices")
plt.show()
```

---

Would you like me to make all 5 experiments into a **formatted PDF lab record** (with output and explanations)?
